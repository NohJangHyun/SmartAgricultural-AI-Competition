{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "391a297a-9499-41d8-91f3-e3a3d8fa0e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d4bf1fb2-3870-4976-b9ec-6bbda9151f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. INPUT\n",
    "input_data = pd.read_csv('2023_smartFarm_AI_hackathon_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c7ffb0de-1334-4df3-872e-5f36ed5ba758",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. PRE_PROCESSING\n",
    "\n",
    "########################################################################################################\n",
    "# 2-1. frmYear(연도), frmWeek(주차) date 기반 imputation\n",
    "# \"date\" 칼럼을 datetime 형식으로 변환해서 \"data1\"에 저장 이후 drop\n",
    "input_data[\"date1\"] = pd.to_datetime(input_data[\"date\"], format=\"%Y%m%d\")\n",
    "input_data[\"date1\"]\n",
    "\n",
    "# \"frmYear\"와 \"frmWeek\" 칼럼의 값이 0인 경우를 확인하고 처리\n",
    "for index, row in input_data.iterrows():\n",
    "    if row[\"frmYear\"] == 0 or row[\"frmWeek\"] == 0:\n",
    "        input_data.at[index, \"frmYear\"] = row[\"date1\"].year\n",
    "        input_data.at[index, \"frmWeek\"] = row[\"date1\"].week\n",
    "\n",
    "# \"frmYear\"와 \"frmWeek\" 칼럼을 정수(int) 형식으로 변환\n",
    "input_data[\"frmYear\"] = input_data[\"frmYear\"].astype(int)\n",
    "input_data[\"frmWeek\"] = input_data[\"frmWeek\"].astype(int)\n",
    "input_data.drop(\"date1\", axis=1, inplace=True)\n",
    "########################################################################################################\n",
    "# 2-2. inCo2(내부CO2), inTp(내부온도), inHd(내부습도), OutTp(외부온도) KNN 기반 imputation\n",
    "# 사용할 칼럼 선택\n",
    "selected_columns = [\"frmAr\", \"frmDov\", \"date\", \"frmYear\", \"frmWeek\", \"inCo2\", \"inTp\", \"inHd\", \"outTp\"]\n",
    "\n",
    "# 0인 값을 NaN(결측치)로 변환\n",
    "input_data[selected_columns] = input_data[selected_columns].replace(0, np.nan)\n",
    "\n",
    "# KNN Imputer 객체 생성\n",
    "imputer = KNNImputer(n_neighbors=5)  # n_neighbors 값은 필요에 따라 조정\n",
    "\n",
    "# 결측치를 채울 칼럼 선택 및 결측치 처리\n",
    "input_data[selected_columns] = imputer.fit_transform(input_data[selected_columns])\n",
    "\n",
    "########################################################################################################\n",
    "# 2-3. acSlrdQy(누적 일사량) mode value로 imputation\n",
    "input_data['acSlrdQy'].replace(0, 995, inplace=True)\n",
    "########################################################################################################\n",
    "# 2-4. WaterUsage(물 사용량), WaterCost(물 사용비용), FertilizerUsage(비료 사용량), FertilizerCost(비료 사용 비용), Mist Cost(미스트 사용비용), MistUsageTime(미스트 사용시간), CO2Cost(CO2사용비용), CO2Usage(CO2사용량) mean value로 imputation\n",
    "input_data['WaterUsage'].replace(0, input_data['WaterUsage'].mean(), inplace=True)\n",
    "input_data['WaterCost'].replace(0, input_data['WaterCost'].mean(), inplace=True)\n",
    "\n",
    "input_data['FertilizerUsage'].replace(0, input_data['FertilizerUsage'].mean(), inplace=True)\n",
    "input_data['FertilizerCost'].replace(0, input_data['FertilizerCost'].mean(), inplace=True)\n",
    "\n",
    "input_data['Mist Cost'].replace(0, input_data['Mist Cost'].mean(), inplace=True)\n",
    "input_data['MistUsageTime'].replace(0, input_data['MistUsageTime'].mean(), inplace=True)\n",
    "\n",
    "input_data['CO2Cost'].replace(0, input_data['CO2Cost'].mean(), inplace=True)\n",
    "input_data['CO2Usage'].replace(0, input_data['CO2Usage'].mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "913a5870-f08e-404d-a109-31b884d480c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. TRAIN/TEST SPLIT\n",
    "input_data = input_data.drop(columns=['frmDist'])\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X = input_data[input_data.drop(columns=['outtrn_cumsum','HeatingEnergyUsage_cumsum']).columns]\n",
    "Y = input_data[['outtrn_cumsum','HeatingEnergyUsage_cumsum']]\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, Y, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c9f7b87-fc4c-4e8f-a822-189305a15ac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최적의 alpha 값: 0.001\n",
      "Mean Squared Error (MSE): 0.1039752814920453\n",
      "R-squared (R2): 0.9142549270750553\n"
     ]
    }
   ],
   "source": [
    "# import numpy as np\n",
    "# from sklearn.linear_model import LassoCV\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# # 무작위 데이터 생성 (예시용)\n",
    "# np.random.seed(0)\n",
    "# X = np.random.rand(100, 2)  # 두 개의 독립 변수를 가진 데이터\n",
    "# y = 2 * X[:, 0] + 3 * X[:, 1] + np.random.rand(100)  # 다중 선형 관계를 갖는 종속 변수 생성\n",
    "\n",
    "# # 데이터를 훈련 세트와 테스트 세트로 분할\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# # LassoCV 모델 생성\n",
    "# alphas = [0.0001,0.001,0.01,0.1, 1.0, 10.0]  # 후보 alpha 값 리스트\n",
    "# lasso_cv_model = LassoCV(alphas=alphas, cv=5)  # 교차 검증을 통한 최적의 alpha 선택\n",
    "\n",
    "# # 최적의 alpha 값을 사용하여 Lasso 모델 훈련\n",
    "# lasso_cv_model.fit(X_train, y_train)\n",
    "\n",
    "# # 테스트 세트에 대한 예측\n",
    "# y_pred = lasso_cv_model.predict(X_test)\n",
    "\n",
    "# # 최적의 alpha 값 확인\n",
    "# best_alpha = lasso_cv_model.alpha_\n",
    "# print(f\"최적의 alpha 값: {best_alpha}\")\n",
    "\n",
    "# # 모델 평가\n",
    "# mse = mean_squared_error(y_test, y_pred)\n",
    "# r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# print(f\"Mean Squared Error (MSE): {mse}\")\n",
    "# print(f\"R-squared (R2): {r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "52a89f78-c4f0-4439-994a-f3a283993019",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\water\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.037e+13, tolerance: 1.014e+10\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\water\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.677e+15, tolerance: 1.959e+12\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    }
   ],
   "source": [
    "# 4. MODEL_TRAIN\n",
    "model = Lasso(alpha=0.001)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b333cabf-ca97-429b-bb43-2244a41695c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. MODEL_PREDICT\n",
    "def calculate_rmse(targets, predictions):\n",
    "    \"\"\"\n",
    "    Calculate the Root Mean Squared Error (RMSE) between predicted and target values.\n",
    "\n",
    "    :param predictions: Predicted values.\n",
    "    :type predictions: array-like\n",
    "    :param targets: Target values.\n",
    "    :type targets: array-like\n",
    "    :return: RMSE value.\n",
    "    :rtype: float\n",
    "    \"\"\"\n",
    "    from sklearn.metrics import mean_squared_error\n",
    "    return np.sqrt(mean_squared_error(targets, predictions))\n",
    "\n",
    "\n",
    "def calculate_R2_score(y_test,y_pred):\n",
    "    return r2_score(y_test, y_pred)\n",
    "\n",
    "\n",
    "rmse = calculate_rmse(y_test, y_pred)\n",
    "r2score = calculate_R2_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fda67b27-99f0-488b-acc2-eabc4873fa49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 239261.37039971075\n",
      "R2_score: 0.5206772664643879\n"
     ]
    }
   ],
   "source": [
    "# 6.OUTPUT\n",
    "print(\"RMSE:\", rmse)\n",
    "print(\"R2_score:\", r2score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91281a4b-eeeb-4700-9bee-ac2ea4b423ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
